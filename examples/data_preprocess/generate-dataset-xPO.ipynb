{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65a756e8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    " <b>Generate training and dev dataset for SLM fine-tuning Using PPO/GRPO</b>\n",
    "\n",
    " 1. Only ASTE: Total 3634 train and 887 dev examples across all the four datasets.\n",
    " 2. ASTE + AOPE + AESC, 10,902 train and 2661 dev examples across all the four datasets.\n",
    " 3. AE + OE + ASTE + AOPE + AESC, 18,170 train and 4435 dev examples across all the four datasets.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46a5ffe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from jinja2 import Environment\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "\n",
    "data_dir = \"/home/azureuser/localfiles/data/aste\"\n",
    "datasets = [\"14res\", \"15res\", \"16res\", \"lap14\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9340196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current Error: NotImplementedError: sequence_length=274 is larger than max_length=256\n",
    "base_reasoning_template_prefix =\"\"\"A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. User: \"\"\"\n",
    "aspect_template = base_reasoning_template_prefix + \"\"\"You are an AI agent skilled at identifying aspect terms from a given sentence. For the sentence provided below extract all the aspect terms and return as a python list of strings, e.g., ['aspect_1', 'aspect_2', ...]. \\nIf no aspect term can be identified then return ['NULL']. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> ['battery', 'screen'] </answer>. \\nSentence: {sentence}\n",
    "Assistant: Let me solve this step by step.\n",
    "<think>\"\"\"\n",
    "opinion_template = base_reasoning_template_prefix + \"\"\"You are an AI agent skilled at identifying opinion terms from a given sentence. For the sentence provided below extract all the opinion terms and return as a python list of strings, e.g., ['aspect_1', 'aspect_2', ...]. \\nIf no aspect term can be identified then return ['NULL']. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> ['battery', 'screen'] </answer>. \\nSentence: {sentence}\n",
    "Assistant: Let me solve this step by step.\n",
    "<think>\"\"\"\n",
    "aope_template = base_reasoning_template_prefix + \"\"\"You are an AI agent skilled at identifying aspect and opinion terms from a given sentence. For the sentence provided below extract all the aspect terms and the corresponding opinion terms and return as a python list of strings, e.g., ['aspect_1 ; opinion_1', 'aspect_2 ; opinion_2', ...]. \\nIf either an aspect or opinion term is not present in the sentence then return 'NULL' in its place. Make sure every element in the list has two sub-elements in it. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> ['battery', 'screen'] </answer>. \\nSentence: {sentence}\n",
    "Assistant: Let me solve this step by step.\n",
    "<think>\"\"\"\n",
    "aesc_template = base_reasoning_template_prefix + \"\"\"You are an AI agent skilled at identifying aspect and sentiment terms from a given sentence. For the sentence provided below extract all the aspect terms and the corresponding sentiment terms and return as a python list of strings, e.g., ['aspect_1 ; sentiment_1', 'aspect_2 ; sentiment_2', ...]. \\nIf either an aspect or sentiment term is not present in the sentence then return 'NULL' in its place. Make sure every element in the list has two sub-elements in it. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> ['battery', 'screen'] </answer>. \\nSentence: {sentence}\n",
    "Assistant: Let me solve this step by step.\n",
    "<think>\"\"\"\n",
    "aste_template = base_reasoning_template_prefix + \"\"\"For the sentence provided below extract all the aspect, opinion and sentiments and return as a python list of strings, e.g., ['aspect_1 ; opinion_1 ; sentiment_1', ...]. \\nThe sentiment is one of the following three, 'POS', 'NEG' and 'NEU', respectively. Return 'NULL' for missing values. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags. \\nSentence: {sentence}\n",
    "Assistant: Let me solve this step by step.\n",
    "<think>\"\"\"\n",
    "\n",
    "def templatize(input_variables: list, template: str):\n",
    "    \"\"\"\n",
    "    Dynamically create prompts based on a template and\n",
    "    user defined values. The template can have placeholders\n",
    "    indicated within curly braces, e.g., {placeholder}\n",
    "    \"\"\"\n",
    "    res = re.findall(r\"[{][a-z_:1-9]+[}]\", template)\n",
    "    if len(input_variables) == 0 or len(res) == 0:\n",
    "        # nothing to decorate\n",
    "        return template\n",
    "\n",
    "    var = [x.strip('{}') for x in res]  # identify the variable names\n",
    "    nvr = [\"{{ \"+v+\" }}\" for v in var]  # rewrite in the Jinja format\n",
    "    s = template\n",
    "    for v1, v2 in zip(res, nvr):\n",
    "        s = s.replace(v1, v2)\n",
    "    environment = Environment()\n",
    "    template = environment.from_string(s)\n",
    "    # t = {k: v for k, v in zip(var, input_variables)}\n",
    "    return template.render({k: v for k, v in zip(var, input_variables)})\n",
    "\n",
    "\n",
    "def make_prefix(dp, template):\n",
    "    sentence = dp['sentence']\n",
    "    prefix = templatize([sentence], template)\n",
    "    return prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e4c6896",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'train'\n",
    "train_dataset = {'dataset': [], 'sentence': [], 'target': []}\n",
    "for dataset in datasets:\n",
    "    with open(os.path.join(data_dir, dataset, f'{split}.sent'), 'r') as fr:\n",
    "        sentences = fr.readlines()\n",
    "        sentences = [e.strip() for e in sentences]\n",
    "\n",
    "    with open(os.path.join(data_dir, dataset, f'{split}.tup'), 'r') as fr:\n",
    "        labels = fr.readlines()\n",
    "        labels = [t.strip() for t in labels]\n",
    "    assert len(sentences) == len(labels), f\"Mismatch in X and Y length\"\n",
    "\n",
    "    for x, y in zip(sentences, labels):\n",
    "        train_dataset['dataset'].append(dataset)\n",
    "        train_dataset['sentence'].append(x)\n",
    "        train_dataset['target'].append(f\"{y.split('|')}\")\n",
    "\n",
    "split = 'dev'\n",
    "dev_dataset = {'dataset': [], 'sentence': [], 'target': []}\n",
    "for dataset in datasets:\n",
    "    with open(os.path.join(data_dir, dataset, f'{split}.sent'), 'r') as fr:\n",
    "        sentences = fr.readlines()\n",
    "        sentences = [e.strip() for e in sentences]\n",
    "\n",
    "    with open(os.path.join(data_dir, dataset, f'{split}.tup'), 'r') as fr:\n",
    "        labels = fr.readlines()\n",
    "        labels = [t.strip() for t in labels]\n",
    "    assert len(sentences) == len(labels), f\"Mismatch in X and Y length\"\n",
    "\n",
    "    for x, y in zip(sentences, labels):\n",
    "        dev_dataset['dataset'].append(dataset)\n",
    "        dev_dataset['sentence'].append(x)\n",
    "        dev_dataset['target'].append(f\"{y.split('|')}\")\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_dataset)\n",
    "dev_dataset = Dataset.from_dict(dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93f0ff9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': '14res',\n",
       " 'sentence': 'But the staff was so horrible to us .',\n",
       " 'target': \"['staff ; horrible ; NEG']\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71742782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3634/3634 [00:01<00:00, 2042.18 examples/s]\n",
      "Map: 100%|██████████| 887/887 [00:00<00:00, 1698.62 examples/s]\n"
     ]
    }
   ],
   "source": [
    "data_source = 'aste'\n",
    "def make_map_fn(split):\n",
    "    def process_fn(example, idx):\n",
    "        question = make_prefix(example, template=aste_template)\n",
    "        solution = {\n",
    "            \"target\": example['target'],\n",
    "        }\n",
    "        qtype = 'aste'\n",
    "        data = {\n",
    "            \"data_source\": data_source,\n",
    "            \"prompt\": [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question,\n",
    "            }],\n",
    "            \"ability\": \"math\",\n",
    "            \"reward_model\": {\n",
    "                \"style\": \"rule\",\n",
    "                \"ground_truth\": solution\n",
    "            },\n",
    "            \"extra_info\": {\n",
    "                'split': split,\n",
    "                'index': idx,\n",
    "                'type': qtype,\n",
    "            }\n",
    "        }\n",
    "        return data\n",
    "    return process_fn\n",
    "\n",
    "train_dataset = train_dataset.map(function=make_map_fn('train'), with_indices=True)\n",
    "dev_dataset = dev_dataset.map(function=make_map_fn('test'), with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62aaa81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:00<00:00, 360.51ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 411.61ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1105319"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.to_parquet(os.path.join(data_dir, 'train.parquet'))\n",
    "dev_dataset.to_parquet(os.path.join(data_dir, 'test.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81c94c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': '14res',\n",
       " 'sentence': 'But the staff was so horrible to us .',\n",
       " 'target': \"['staff ; horrible ; NEG']\",\n",
       " 'data_source': 'aste',\n",
       " 'prompt': [{'content': \"A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. User: For the sentence provided below extract all the aspect terms, corresponding opinion terms and sentiments and return as a python list of strings, e.g., ['aspect_1 ; opinion_1 ; sentiment_1', 'aspect_2 ; opinion_2 ; sentiment_2', ...]. \\nThe sentiment is one of the following three, 'POS', 'NEG' and 'NEU' for positive, negative and neutral sentiment, respectively. If either an aspect or opinion term is not present in the sentence then return 'NULL' in its place. Make sure every element in the list has three sub-elements in it. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags. \\nSentence: But the staff was so horrible to us . \\nAssistant: Let me solve this step by step.\\n<think>\",\n",
       "   'role': 'user'}],\n",
       " 'ability': 'math',\n",
       " 'reward_model': {'ground_truth': {'target': \"['staff ; horrible ; NEG']\"},\n",
       "  'style': 'rule'},\n",
       " 'extra_info': {'index': 0, 'split': 'train', 'type': 'aste'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef042dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
